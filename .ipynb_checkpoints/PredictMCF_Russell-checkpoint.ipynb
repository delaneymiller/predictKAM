{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages, data, and define functions\n",
    "### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "\n",
    "import scipy.io as sio #\n",
    "import tensorflow as tf #\n",
    "import numpy as np #\n",
    "from numpy import savetxt\n",
    "import scipy.signal\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow.python.keras.backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "import matplotlib.pyplot as plt #\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import scipy.stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag if 3D, frontal, or sagittal\n",
    "modeltype = '3D' # Options are '3D', 'frontal', or 'sagittal'\n",
    "    \n",
    "# Configure to use CPU or GPU \n",
    "# 'GPU' : 1 if you are using a GPU, 0 otherwise\n",
    "config = tf.compat.v1.ConfigProto(device_count = {'CPU' : 1, 'GPU' : 0})\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for later in script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_numpy(data,labels,model):\n",
    "    y_pred2 = model.predict(data)\n",
    "    mse = np.mean(np.square(y_pred2-labels))\n",
    "    r2 = np.square(np.corrcoef(labels.T,y_pred2.T)[0,1])\n",
    "    mae = np.mean(np.abs(y_pred2-labels))\n",
    "    return r2,mse,mae\n",
    "\n",
    "def PredictMCF(model,inputData):\n",
    "    predictedMCF = model.predict(inputData[range(inputData.shape[0]),:])\n",
    "    return predictedMCF\n",
    "\n",
    "def PlotMCFpredictions(trueMCF,predictedMCF):\n",
    "    # Plot predicted and true peaks vs. step\n",
    "    plt.figure(1)\n",
    "    truePlot = plt.plot(trueMCF)\n",
    "    predPlot = plt.plot(predictedMCF)\n",
    "    plt.ylabel('MCF Peak Comparison')\n",
    "    plt.xlabel('Step')\n",
    "    plt.legend(('True','Predicted'),loc=4);\n",
    "\n",
    "    # Plot predicted vs. true peaks\n",
    "    plt.figure(2)\n",
    "    ax = plt.plot(trueMCF,predictedMCF,'.',color=(45/255, 107/255, 179/255),alpha=0.05)\n",
    "    plt.axis('equal')\n",
    "    plt.ylabel('Predicted MCF')\n",
    "    plt.xlabel('True MCF')\n",
    "    plt.ylim(1,4)\n",
    "    plt.xlim(1,4)\n",
    "    plt.plot([-1,4],[-1,4],'k')\n",
    "    plt.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "    \n",
    "def PlotTrainingCurves(trainResults,devResults,epochCount):\n",
    "    # Plot training curves\n",
    "    lossPlt = plt.plot(np.arange(1,epochCount+1),train_loss[range(epochCount)])\n",
    "    DevlossPlt = plt.plot(np.arange(1,epochCount+1),dev_loss[range(epochCount)])\n",
    "\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.xlabel('Epoch Number');\n",
    "    plt.legend(('Training','Dev'))\n",
    "\n",
    "    plt.figure(2)\n",
    "    r2Plt = plt.plot(np.arange(1,epochCount+1),train_r2[range(epochCount)])\n",
    "    devr2Plt = plt.plot(np.arange(1,epochCount+1),dev_r2[range(epochCount)])\n",
    "    plt.ylim([.2, 1])\n",
    "    plt.ylabel('r^2')\n",
    "    plt.xlabel('Epoch Number');\n",
    "    plt.legend(('Training','Dev'))\n",
    "    \n",
    "if modeltype not in ['3D', 'frontal', 'sagittal']:\n",
    "    raise ValueError(\"Error: Options are '3D' 'frontal' or 'sagittal'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data\n",
    "inputData = sio.loadmat(\"Data\\inputData.mat\")\n",
    "# inputData = np.load(\"Data\\inputData.npy\").flat[0]\n",
    "\n",
    "# Load input data (X)\n",
    "ik = inputData[\"ik\"] # time + inverse kinematics (101, 32, 7779)\n",
    "ik_input = ik[:,1:,:]\n",
    "time_input = ik[:,0,:]\n",
    "leg = inputData[\"leg\"].T  # stance leg (per step) (7779,1)\n",
    "subject = inputData[\"subject\"].T  # subject number (per step) (7779,1)\n",
    "\n",
    "# Load output data (Y)\n",
    "MCF = inputData[\"MCF\"] # MCF over time (101, 7779)\n",
    "peakMCF_early = inputData[\"peakMCF_early\"].T # early stance peak\n",
    "peakMCF_late = inputData[\"peakMCF_late\"].T # late stance peak\n",
    "minMCF = inputData[\"minMCF\"].T # mid stance valley\n",
    "\n",
    "# Print output dimensions\n",
    "print(\"Inverse kinematics: \" + str(ik_input.shape))\n",
    "print(\"Time: \" + str(time_input.shape))\n",
    "print(\"Stance leg: \" + str(leg.shape))\n",
    "print(\"Subject number: \" + str(subject.shape))\n",
    "print(\"Medial contact force: \" + str(MCF.shape))\n",
    "print(\"Early-stance MCF peak: \" + str(peakMCF_early.shape))\n",
    "print(\"Late-stance MCF peak: \" + str(peakMCF_late.shape))\n",
    "print(\"Mid-stance MCF valley: \" + str(minMCF.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leg dimensions (nSamples, 101, 1)\n",
    "legBin = np.expand_dims(np.tile(leg,(1,101)),axis=2)\n",
    "print(\"Leg: \" + str(legBin.shape))\n",
    "# Adjust joint angles to correct dimensions (nSamples, nTimesteps, nFeatures)\n",
    "angles = np.transpose(ik_input, axes=[2, 0, 1])\n",
    "print(\"Joint angles: \" + str(angles.shape))\n",
    "# Time dimensions (nSamples, 1, 1)\n",
    "time_input = time_input - time_input[0,:]\n",
    "time = np.expand_dims(np.transpose(time_input), axis = 2)\n",
    "print(\"Time: \" + str(time.shape))\n",
    "\n",
    "# Concatenate legBin with angles\n",
    "inputMat = np.concatenate((angles, legBin), axis = 2)\n",
    "\n",
    "# Resample (nTimesteps = 16)\n",
    "inputMat = scipy.signal.resample(inputMat,16, axis = 1)\n",
    "\n",
    "# Use positions from first half of stance\n",
    "# firstHalfStance = range(0,16,2)\n",
    "#inputMat = inputMat[:,0:8,:] # nSamples x nTimesteps x nFeatures\n",
    "print(\"Input shape: \" + str(inputMat.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format output MCF (currently just early stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the output (nSamples, 1, 1)\n",
    "output = np.expand_dims(peakMCF_late,axis=2) # figure out how to do 2 peaks\n",
    "print(\"Output shape is \" + str(output.shape))\n",
    "\n",
    "plt.plot(output[:,0,0]);\n",
    "plt.ylabel(\"Peak MCF (BW)\");\n",
    "plt.xlabel(\"Step\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide into train, development, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed so it is reproducible\n",
    "np.random.seed(1)\n",
    "nSubjects = len(np.unique(subject)) # 68 subjects\n",
    "subject_shuffle = np.unique(subject)\n",
    "np.random.shuffle(subject_shuffle)\n",
    "\n",
    "# 90-10-10 split (54-7-7 subjects)\n",
    "train, dev, test = np.split(subject_shuffle, [int(0.8*len(subject_shuffle)), int(0.9*len(subject_shuffle))])\n",
    "\n",
    "# Find step indicies for each subject in each set (Boswell code)\n",
    "trainInds = np.array(0)\n",
    "for i in train:\n",
    "    trainInds = np.append(trainInds,np.argwhere(subject==i))\n",
    "trainInds = trainInds[1:]\n",
    "    \n",
    "devInds = np.array(0)\n",
    "for i in dev:\n",
    "    devInds = np.append(devInds,np.argwhere(subject==i))\n",
    "devInds = devInds[1:]\n",
    "\n",
    "testInds = np.array(0)\n",
    "for i in test:\n",
    "    testInds = np.append(testInds,np.argwhere(subject==i))\n",
    "testInds = testInds[1:]\n",
    "\n",
    "# Build training, development, and test inputs and labels\n",
    "trainInput_full = inputMat[trainInds,:,:]\n",
    "print(trainInput_full.shape)\n",
    "trainInput_full = trainInput_full.reshape((trainInput_full.shape[0],-1))\n",
    "trainLabels = output[trainInds,0]\n",
    "\n",
    "devInput_full = inputMat[devInds,:,:]\n",
    "devInput_full = devInput_full.reshape((devInput_full.shape[0],-1))\n",
    "devLabels = output[devInds,0]\n",
    "\n",
    "testInput_full = inputMat[testInds,:,:]\n",
    "testInput_full = testInput_full.reshape((testInput_full.shape[0],-1))\n",
    "testLabels = output[testInds,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove redundant leg inputs (and at some point lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if modeltype == '3D':\n",
    "    # features removed by the lasso (saved from R)\n",
    "    # lassoDeletedInds = inputData[\"lassoDeletedInds3D\"]\n",
    "    \n",
    "    #Positions to remove - every 40th index is leg. Leave the first one\n",
    "    # inputIndicies = np.delete(np.arange(0,320),np.unique(np.concatenate((np.arange(79,320,40),lassoDeletedInds))))\n",
    "    \n",
    "#elif np.logical_or(modeltype == 'frontal',modeltype=='sagittal'):\n",
    "    #Positions to remove - every 28th index is leg. Leave the first one\n",
    "    # inputIndicies = np.delete(np.arange(0,216),np.arange(53,216,27))\n",
    "\n",
    "# Extract indices of leg (every 32nd index, leave first one)\n",
    "inputIdx = np.delete(np.arange(0,256), np.arange(63, 256, 32))\n",
    "\n",
    "# Remove input features\n",
    "trainInput = trainInput_full[:,inputIdx]\n",
    "devInput = devInput_full[:,inputIdx]\n",
    "testInput = testInput_full[:,inputIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pre-trained weights (N/A b/c different input features)\n",
    "Note that results may vary slightly from the paper for several reasons: <br />\n",
    "1) The models in the paper were trained with a GPU, results vary slightly when trained with CPU <br />\n",
    "2) Small floating-point differences when we re-packaged dataset for distribution <br />\n",
    "3) For test set results, we randomly sample 400 steps from each leg in the set (to mitigate the effect of walking speed or stride frequency on outcome metrics), while the results here are for all steps in the test set. We also bootstrap resampled the test set 10,000 times to compute the mean and confidence intervals of performance metrics, making the mean performance metric vary slightly from the results on the uniformly-sampled test set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WON'T WORK BECAUSE WE HAVE DIFFERENT INPUT FEATURE SIZE\n",
    "# Import previously trained model and weights for prediction\n",
    "json_file = open(\"PretrainedModels/NeuralNet_\" + modeltype + \".json\", 'r')\n",
    "pretrainedModel_json = json_file.read()\n",
    "json_file.close()\n",
    "pretrainedModel = keras.models.model_from_json(pretrainedModel_json)\n",
    "# load weights into new model\n",
    "pretrainedModel.load_weights(\"PretrainedModels/NeuralNet_\" + modeltype + \"_weights.h5\")\n",
    "pretrainedModel.compile(loss='mean_squared_error',optimizer='adam')\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "testPredictions_pretrainedModel = PredictMCF(pretrainedModel,testInput)\n",
    "\n",
    "# Plot predicted vs true KAM predictions\n",
    "PlotMCFpredictions(testLabels,testPredictions_pretrainedModel)\n",
    "\n",
    "# Print test r2 and MSE\n",
    "test_r2 = r2_numpy(testInput,testLabels,pretrainedModel)\n",
    "print('r2 = ' + str(test_r2[0]) + ', MSE = ' + str(test_r2[1])+ ', MAE = ' + str(test_r2[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new model from scratch\n",
    "### Construct new model (not modified from Boswell et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2 = np.empty((1000,1))\n",
    "dev_r2 = np.empty((1000,1))\n",
    "train_loss = np.empty((1000,1))\n",
    "dev_loss = np.empty((1000,1))\n",
    "epochCount = 0 ;\n",
    "\n",
    "def construct_model(nHiddenUnits, nHiddenLayers, input_dim, output_dim):\n",
    "    np.random.seed(1)\n",
    "    tf.compat.v1.set_random_seed(1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(800,input_shape = (input_dim,), kernel_initializer=glorot_normal(seed=None) , activation='relu')) #,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01)))\n",
    "    for i in range(nHiddenLayers-1):\n",
    "        model.add(Dropout(0.01))\n",
    "        model.add(Dense(nHiddenUnits , kernel_initializer=glorot_normal(seed=None) , activation='relu')) #,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01)))\n",
    "    \n",
    "    model.add(Dropout(0.01))\n",
    "    model.add(Dense(1,kernel_initializer=glorot_normal(seed=None),activation='linear'))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model = construct_model(nHiddenUnits = 100, nHiddenLayers = 1, input_dim = trainInput.shape[1], output_dim = trainLabels.shape[1])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpochs = 30\n",
    "models = [] ;\n",
    "\n",
    "\n",
    "train_r2 = np.zeros((1000,1))\n",
    "dev_r2 = np.zeros((1000,1))\n",
    "train_loss = np.zeros((1000,1))\n",
    "dev_loss = np.zeros((1000,1))\n",
    "train_mae = np.zeros((1000,1))\n",
    "dev_mae = np.zeros((1000,1))\n",
    "epochCount = 0 ;\n",
    "\n",
    "thisModel = construct_model(nHiddenUnits = 100, nHiddenLayers = 1, input_dim = trainInput.shape[1], output_dim = trainLabels.shape[1])\n",
    "thisModel.summary()\n",
    "\n",
    "for i in range(nEpochs):\n",
    "    print('Epoch ' + str(i+1) + ' of ' + str(nEpochs) + '.')\n",
    "\n",
    "    history = thisModel.fit(trainInput,trainLabels, epochs=1 , batch_size = 32, shuffle = True, verbose=2)\n",
    "\n",
    "    train_r2[epochCount], train_loss[epochCount], train_mae[epochCount] = r2_numpy(trainInput,trainLabels,thisModel)\n",
    "    dev_r2[epochCount], dev_loss[epochCount], dev_mae[epochCount] = r2_numpy(devInput,devLabels,thisModel)\n",
    "    print('Train_loss = ' + str(train_loss[epochCount]) + ', Train_r2 = ' + str(train_r2[epochCount]) + ', Dev_loss = ' + str(dev_loss[epochCount]) + ', Dev_r2 = ' + str(dev_r2[epochCount]))\n",
    "\n",
    "    devBest = np.argmin(dev_loss[dev_loss !=0])\n",
    "    if i-devBest > 4: # stop training if dev hasn't gotten better in last 5 epochs\n",
    "        print('No Longer Improving')\n",
    "        break\n",
    "        \n",
    "    if i == devBest:\n",
    "        model = keras.models.clone_model(thisModel)\n",
    "        model.set_weights(thisModel.get_weights())\n",
    "        print('saving best model')\n",
    "\n",
    "    epochCount = epochCount + 1 ;\n",
    "            \n",
    "bestEpoch = np.argmin(dev_loss[dev_loss !=0])\n",
    "print('For Best Epoch:' + str(bestEpoch+1) + ' Train r2 =' + str(train_r2[bestEpoch]) + ' Dev r2 =' + str(dev_r2[bestEpoch]))\n",
    "\n",
    "# Plot training curves\n",
    "PlotTrainingCurves(train_r2,dev_r2,epochCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model - Architecture Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nHiddenUnitsArray = np.array([1,2,5,10,20,50,100,250,500,1000,2000])\n",
    "nHiddenLayersArray = np.array([1,2,3,4,5,7,10,12,15,20,25])\n",
    "a1, a2 = np.meshgrid(nHiddenUnitsArray, nHiddenLayersArray)\n",
    "# hyperParamsArray contains 2 colums: nHiddenUnits and nHiddenLayers\n",
    "hyperParamsArray = np.concatenate((a1.reshape(-1,1),a2.reshape(-1,1)),axis=1) \n",
    "\n",
    "nConditions = hyperParamsArray.shape[0]\n",
    "resultsArray = np.zeros((nConditions,5))\n",
    "\n",
    "resultsArray[0,:] = [1,2,3,4,5]\n",
    "# print(resultsArray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Condition  0  of  121 . nHiddenUnits =  1 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  1  of  121 . nHiddenUnits =  2 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  2  of  121 . nHiddenUnits =  5 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  3  of  121 . nHiddenUnits =  10 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  4  of  121 . nHiddenUnits =  20 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  5  of  121 . nHiddenUnits =  50 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  6  of  121 . nHiddenUnits =  100 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  7  of  121 . nHiddenUnits =  250 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  8  of  121 . nHiddenUnits =  500 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  9  of  121 . nHiddenUnits =  1000 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  10  of  121 . nHiddenUnits =  2000 . nHiddenLayers =  1 .\n",
      "For Best Epoch:13 Train r2 =[0.9297211] Dev r2 =[0.49183791]\n",
      "\n",
      " Condition  11  of  121 . nHiddenUnits =  1 . nHiddenLayers =  2 .\n",
      "C:\\Users\\rmm40\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\rmm40\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  12  of  121 . nHiddenUnits =  2 . nHiddenLayers =  2 .\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  13  of  121 . nHiddenUnits =  5 . nHiddenLayers =  2 .\n",
      "For Best Epoch:21 Train r2 =[0.94249872] Dev r2 =[0.44189597]\n",
      "\n",
      " Condition  14  of  121 . nHiddenUnits =  10 . nHiddenLayers =  2 .\n",
      "For Best Epoch:10 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  15  of  121 . nHiddenUnits =  20 . nHiddenLayers =  2 .\n",
      "For Best Epoch:13 Train r2 =[0.94815733] Dev r2 =[0.39814677]\n",
      "\n",
      " Condition  16  of  121 . nHiddenUnits =  50 . nHiddenLayers =  2 .\n",
      "For Best Epoch:6 Train r2 =[0.93536727] Dev r2 =[0.51610843]\n",
      "\n",
      " Condition  17  of  121 . nHiddenUnits =  100 . nHiddenLayers =  2 .\n",
      "For Best Epoch:7 Train r2 =[0.92354364] Dev r2 =[0.49105762]\n",
      "\n",
      " Condition  18  of  121 . nHiddenUnits =  250 . nHiddenLayers =  2 .\n",
      "For Best Epoch:15 Train r2 =[0.92610885] Dev r2 =[0.43865097]\n",
      "\n",
      " Condition  19  of  121 . nHiddenUnits =  500 . nHiddenLayers =  2 .\n",
      "For Best Epoch:14 Train r2 =[0.93318449] Dev r2 =[0.43583491]\n",
      "\n",
      " Condition  20  of  121 . nHiddenUnits =  1000 . nHiddenLayers =  2 .\n",
      "For Best Epoch:9 Train r2 =[0.94933253] Dev r2 =[0.42631827]\n",
      "\n",
      " Condition  21  of  121 . nHiddenUnits =  2000 . nHiddenLayers =  2 .\n",
      "For Best Epoch:24 Train r2 =[0.91844267] Dev r2 =[0.67677887]\n",
      "\n",
      " Condition  22  of  121 . nHiddenUnits =  1 . nHiddenLayers =  3 .\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  23  of  121 . nHiddenUnits =  2 . nHiddenLayers =  3 .\n",
      "For Best Epoch:10 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  24  of  121 . nHiddenUnits =  5 . nHiddenLayers =  3 .\n",
      "For Best Epoch:4 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  25  of  121 . nHiddenUnits =  10 . nHiddenLayers =  3 .\n",
      "For Best Epoch:5 Train r2 =[0.84611803] Dev r2 =[0.34814039]\n",
      "\n",
      " Condition  26  of  121 . nHiddenUnits =  20 . nHiddenLayers =  3 .\n",
      "For Best Epoch:10 Train r2 =[0.93469699] Dev r2 =[0.6107907]\n",
      "\n",
      " Condition  27  of  121 . nHiddenUnits =  50 . nHiddenLayers =  3 .\n",
      "For Best Epoch:1 Train r2 =[0.86207698] Dev r2 =[0.52327337]\n",
      "\n",
      " Condition  28  of  121 . nHiddenUnits =  100 . nHiddenLayers =  3 .\n",
      "For Best Epoch:8 Train r2 =[0.92809455] Dev r2 =[0.57338957]\n",
      "\n",
      " Condition  29  of  121 . nHiddenUnits =  250 . nHiddenLayers =  3 .\n",
      "For Best Epoch:10 Train r2 =[0.94259656] Dev r2 =[0.62604964]\n",
      "\n",
      " Condition  30  of  121 . nHiddenUnits =  500 . nHiddenLayers =  3 .\n",
      "For Best Epoch:10 Train r2 =[0.93435173] Dev r2 =[0.69786638]\n",
      "\n",
      " Condition  31  of  121 . nHiddenUnits =  1000 . nHiddenLayers =  3 .\n",
      "For Best Epoch:13 Train r2 =[0.93677072] Dev r2 =[0.67859756]\n",
      "\n",
      " Condition  32  of  121 . nHiddenUnits =  2000 . nHiddenLayers =  3 .\n",
      "For Best Epoch:15 Train r2 =[0.93770554] Dev r2 =[0.50373473]\n",
      "\n",
      " Condition  33  of  121 . nHiddenUnits =  1 . nHiddenLayers =  4 .\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  34  of  121 . nHiddenUnits =  2 . nHiddenLayers =  4 .\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  35  of  121 . nHiddenUnits =  5 . nHiddenLayers =  4 .\n",
      "For Best Epoch:6 Train r2 =[0.92475507] Dev r2 =[0.43833282]\n",
      "\n",
      " Condition  36  of  121 . nHiddenUnits =  10 . nHiddenLayers =  4 .\n",
      "For Best Epoch:6 Train r2 =[0.90036343] Dev r2 =[0.41229494]\n",
      "\n",
      " Condition  37  of  121 . nHiddenUnits =  20 . nHiddenLayers =  4 .\n",
      "For Best Epoch:10 Train r2 =[0.94099564] Dev r2 =[0.60953046]\n",
      "\n",
      " Condition  38  of  121 . nHiddenUnits =  50 . nHiddenLayers =  4 .\n",
      "For Best Epoch:10 Train r2 =[0.93860823] Dev r2 =[0.71014463]\n",
      "\n",
      " Condition  39  of  121 . nHiddenUnits =  100 . nHiddenLayers =  4 .\n",
      "For Best Epoch:6 Train r2 =[0.91279362] Dev r2 =[0.52462267]\n",
      "\n",
      " Condition  40  of  121 . nHiddenUnits =  250 . nHiddenLayers =  4 .\n",
      "For Best Epoch:9 Train r2 =[0.92417285] Dev r2 =[0.47438445]\n",
      "\n",
      " Condition  41  of  121 . nHiddenUnits =  500 . nHiddenLayers =  4 .\n",
      "For Best Epoch:5 Train r2 =[0.92359473] Dev r2 =[0.52316924]\n",
      "\n",
      " Condition  42  of  121 . nHiddenUnits =  1000 . nHiddenLayers =  4 .\n",
      "For Best Epoch:5 Train r2 =[0.92986764] Dev r2 =[0.60915228]\n",
      "\n",
      " Condition  43  of  121 . nHiddenUnits =  2000 . nHiddenLayers =  4 .\n",
      "For Best Epoch:4 Train r2 =[0.93363513] Dev r2 =[0.46095371]\n",
      "\n",
      " Condition  44  of  121 . nHiddenUnits =  1 . nHiddenLayers =  5 .\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  45  of  121 . nHiddenUnits =  2 . nHiddenLayers =  5 .\n",
      "For Best Epoch:10 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  46  of  121 . nHiddenUnits =  5 . nHiddenLayers =  5 .\n",
      "For Best Epoch:2 Train r2 =[0.90651417] Dev r2 =[0.48272486]\n",
      "\n",
      " Condition  47  of  121 . nHiddenUnits =  10 . nHiddenLayers =  5 .\n",
      "For Best Epoch:3 Train r2 =[0.88862496] Dev r2 =[0.44745526]\n",
      "\n",
      " Condition  48  of  121 . nHiddenUnits =  20 . nHiddenLayers =  5 .\n",
      "For Best Epoch:7 Train r2 =[0.91792705] Dev r2 =[0.64080151]\n",
      "\n",
      " Condition  49  of  121 . nHiddenUnits =  50 . nHiddenLayers =  5 .\n",
      "For Best Epoch:7 Train r2 =[0.94133745] Dev r2 =[0.69768899]\n",
      "\n",
      " Condition  50  of  121 . nHiddenUnits =  100 . nHiddenLayers =  5 .\n",
      "For Best Epoch:7 Train r2 =[0.92875792] Dev r2 =[0.59165681]\n",
      "\n",
      " Condition  51  of  121 . nHiddenUnits =  250 . nHiddenLayers =  5 .\n",
      "For Best Epoch:7 Train r2 =[0.93658571] Dev r2 =[0.55620996]\n",
      "\n",
      " Condition  52  of  121 . nHiddenUnits =  500 . nHiddenLayers =  5 .\n",
      "For Best Epoch:10 Train r2 =[0.92868137] Dev r2 =[0.44630724]\n",
      "\n",
      " Condition  53  of  121 . nHiddenUnits =  1000 . nHiddenLayers =  5 .\n",
      "For Best Epoch:11 Train r2 =[0.94544214] Dev r2 =[0.47882683]\n",
      "\n",
      " Condition  54  of  121 . nHiddenUnits =  2000 . nHiddenLayers =  5 .\n",
      "For Best Epoch:8 Train r2 =[0.94073928] Dev r2 =[0.17556344]\n",
      "\n",
      " Condition  55  of  121 . nHiddenUnits =  1 . nHiddenLayers =  7 .\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  56  of  121 . nHiddenUnits =  2 . nHiddenLayers =  7 .\n",
      "For Best Epoch:4 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  57  of  121 . nHiddenUnits =  5 . nHiddenLayers =  7 .\n",
      "For Best Epoch:1 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  58  of  121 . nHiddenUnits =  10 . nHiddenLayers =  7 .\n",
      "For Best Epoch:8 Train r2 =[0.93516063] Dev r2 =[0.56057719]\n",
      "\n",
      " Condition  59  of  121 . nHiddenUnits =  20 . nHiddenLayers =  7 .\n",
      "For Best Epoch:5 Train r2 =[0.92958859] Dev r2 =[0.53717114]\n",
      "\n",
      " Condition  60  of  121 . nHiddenUnits =  50 . nHiddenLayers =  7 .\n",
      "For Best Epoch:7 Train r2 =[0.93885791] Dev r2 =[0.56005092]\n",
      "\n",
      " Condition  61  of  121 . nHiddenUnits =  100 . nHiddenLayers =  7 .\n",
      "For Best Epoch:11 Train r2 =[0.9442233] Dev r2 =[0.66246676]\n",
      "\n",
      " Condition  62  of  121 . nHiddenUnits =  250 . nHiddenLayers =  7 .\n",
      "For Best Epoch:11 Train r2 =[0.94941306] Dev r2 =[0.51537967]\n",
      "\n",
      " Condition  63  of  121 . nHiddenUnits =  500 . nHiddenLayers =  7 .\n",
      "For Best Epoch:7 Train r2 =[0.93711032] Dev r2 =[0.55229571]\n",
      "\n",
      " Condition  64  of  121 . nHiddenUnits =  1000 . nHiddenLayers =  7 .\n",
      "For Best Epoch:7 Train r2 =[0.94462121] Dev r2 =[0.4669517]\n",
      "\n",
      " Condition  65  of  121 . nHiddenUnits =  2000 . nHiddenLayers =  7 .\n",
      "For Best Epoch:5 Train r2 =[0.94234874] Dev r2 =[0.40434468]\n",
      "\n",
      " Condition  66  of  121 . nHiddenUnits =  1 . nHiddenLayers =  10 .\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  67  of  121 . nHiddenUnits =  2 . nHiddenLayers =  10 .\n",
      "For Best Epoch:2 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  68  of  121 . nHiddenUnits =  5 . nHiddenLayers =  10 .\n",
      "For Best Epoch:2 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  69  of  121 . nHiddenUnits =  10 . nHiddenLayers =  10 .\n",
      "For Best Epoch:8 Train r2 =[0.94108462] Dev r2 =[0.56392339]\n",
      "\n",
      " Condition  70  of  121 . nHiddenUnits =  20 . nHiddenLayers =  10 .\n",
      "For Best Epoch:18 Train r2 =[0.95840046] Dev r2 =[0.62585666]\n",
      "\n",
      " Condition  71  of  121 . nHiddenUnits =  50 . nHiddenLayers =  10 .\n",
      "For Best Epoch:9 Train r2 =[0.93488836] Dev r2 =[0.69640558]\n",
      "\n",
      " Condition  72  of  121 . nHiddenUnits =  100 . nHiddenLayers =  10 .\n",
      "For Best Epoch:6 Train r2 =[0.92546697] Dev r2 =[0.68552341]\n",
      "\n",
      " Condition  73  of  121 . nHiddenUnits =  250 . nHiddenLayers =  10 .\n",
      "For Best Epoch:4 Train r2 =[0.93447209] Dev r2 =[0.63358879]\n",
      "\n",
      " Condition  74  of  121 . nHiddenUnits =  500 . nHiddenLayers =  10 .\n",
      "For Best Epoch:5 Train r2 =[0.93345581] Dev r2 =[0.56024814]\n",
      "\n",
      " Condition  75  of  121 . nHiddenUnits =  1000 . nHiddenLayers =  10 .\n",
      "For Best Epoch:12 Train r2 =[0.9455547] Dev r2 =[0.60248256]\n",
      "\n",
      " Condition  76  of  121 . nHiddenUnits =  2000 . nHiddenLayers =  10 .\n",
      "For Best Epoch:11 Train r2 =[0.95282593] Dev r2 =[0.2069594]\n",
      "\n",
      " Condition  77  of  121 . nHiddenUnits =  1 . nHiddenLayers =  12 .\n",
      "For Best Epoch:9 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  78  of  121 . nHiddenUnits =  2 . nHiddenLayers =  12 .\n",
      "For Best Epoch:1 Train r2 =[0.38865519] Dev r2 =[2.30785294e-05]\n",
      "\n",
      " Condition  79  of  121 . nHiddenUnits =  5 . nHiddenLayers =  12 .\n",
      "For Best Epoch:3 Train r2 =[nan] Dev r2 =[nan]\n",
      "\n",
      " Condition  80  of  121 . nHiddenUnits =  10 . nHiddenLayers =  12 .\n",
      "For Best Epoch:14 Train r2 =[0.94923071] Dev r2 =[0.62637327]\n",
      "\n",
      " Condition  81  of  121 . nHiddenUnits =  20 . nHiddenLayers =  12 .\n",
      "For Best Epoch:6 Train r2 =[0.9438895] Dev r2 =[0.55234789]\n",
      "\n",
      " Condition  82  of  121 . nHiddenUnits =  50 . nHiddenLayers =  12 .\n",
      "For Best Epoch:10 Train r2 =[0.93832739] Dev r2 =[0.53241832]\n",
      "\n",
      " Condition  83  of  121 . nHiddenUnits =  100 . nHiddenLayers =  12 .\n",
      "For Best Epoch:3 Train r2 =[0.92949635] Dev r2 =[0.61516417]\n",
      "\n",
      " Condition  84  of  121 . nHiddenUnits =  250 . nHiddenLayers =  12 .\n",
      "For Best Epoch:4 Train r2 =[0.93364213] Dev r2 =[0.44047041]\n",
      "\n",
      " Condition  85  of  121 . nHiddenUnits =  500 . nHiddenLayers =  12 .\n",
      "For Best Epoch:3 Train r2 =[0.93220514] Dev r2 =[0.3772508]\n",
      "\n",
      " Condition  86  of  121 . nHiddenUnits =  1000 . nHiddenLayers =  12 .\n",
      "For Best Epoch:6 Train r2 =[0.94299118] Dev r2 =[0.52575466]\n",
      "\n",
      " Condition  87  of  121 . nHiddenUnits =  2000 . nHiddenLayers =  12 .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-dee094e1c4fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# print('Epoch ' + str(i+1) + ' of ' + str(nEpochs) + '.')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthisModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#verbose = 2 to print results by epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtrain_r2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepochCount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepochCount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mae\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepochCount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthisModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nHiddenUnitsArray = np.array([1,2,5,10,20,50,100,250,500,1000,2000])\n",
    "nHiddenLayersArray = np.array([1,2,3,4,5,7,10,12,15,20,25])\n",
    "a1, a2 = np.meshgrid(nHiddenUnitsArray, nHiddenLayersArray)\n",
    "# hyperParamsArray contains 2 colums: nHiddenUnits and nHiddenLayers\n",
    "hyperParamsArray = np.concatenate((a1.reshape(-1,1),a2.reshape(-1,1)),axis=1) \n",
    "\n",
    "nConditions = hyperParamsArray.shape[0]\n",
    "# resultsArray contains 5 colums: bestEpoch, trainLoss, devLoss, trainR2, devR2. Each row corresponds to a row of model hyperparams from hyperParamsArray\n",
    "resultsArray = np.zeros((nConditions,5))\n",
    "\n",
    "for k in range(nConditions):\n",
    "\n",
    "    nHiddenUnits = hyperParamsArray[k,0]\n",
    "    nHiddenLayers = hyperParamsArray[k,1]\n",
    "    print(\"\\n Condition \", k, \" of \",nConditions,\". nHiddenUnits = \", nHiddenUnits, \". nHiddenLayers = \", nHiddenLayers, \".\")\n",
    "\n",
    "    nEpochs = 50\n",
    "    models = [] ;\n",
    "\n",
    "    train_r2 = np.zeros((1000,1))\n",
    "    dev_r2 = np.zeros((1000,1))\n",
    "    train_loss = np.zeros((1000,1))\n",
    "    dev_loss = np.zeros((1000,1))\n",
    "    train_mae = np.zeros((1000,1))\n",
    "    dev_mae = np.zeros((1000,1))\n",
    "    epochCount = 0 ;\n",
    "\n",
    "    thisModel = construct_model(nHiddenUnits, nHiddenLayers, input_dim = trainInput.shape[1], output_dim = trainLabels.shape[1])\n",
    "    #thisModel.summary()\n",
    "\n",
    "    for i in range(nEpochs):\n",
    "        # print('Epoch ' + str(i+1) + ' of ' + str(nEpochs) + '.')\n",
    "\n",
    "        history = thisModel.fit(trainInput,trainLabels, epochs=1 , batch_size = 32, shuffle = True, verbose=0) #verbose = 2 to print results by epoch\n",
    "\n",
    "        train_r2[epochCount], train_loss[epochCount], train_mae[epochCount] = r2_numpy(trainInput,trainLabels,thisModel)\n",
    "        dev_r2[epochCount], dev_loss[epochCount], dev_mae[epochCount] = r2_numpy(devInput,devLabels,thisModel)\n",
    "        # print('Train_loss = ' + str(train_loss[epochCount]) + ', Train_r2 = ' + str(train_r2[epochCount]) + ', Dev_loss = ' + str(dev_loss[epochCount]) + ', Dev_r2 = ' + str(dev_r2[epochCount]))\n",
    "\n",
    "        devBest = np.argmin(dev_loss[dev_loss !=0])\n",
    "        if i-devBest > 4: # stop training if dev hasn't gotten better in last 5 epochs\n",
    "            # print('No Longer Improving')\n",
    "            break\n",
    "            \n",
    "        if i == devBest:\n",
    "            model = keras.models.clone_model(thisModel)\n",
    "            model.set_weights(thisModel.get_weights())\n",
    "            # print('saving best model')\n",
    "\n",
    "        epochCount = epochCount + 1 ;\n",
    "                \n",
    "    bestEpoch = np.argmin(dev_loss[dev_loss !=0])\n",
    "    print('For Best Epoch:' + str(bestEpoch+1) + ' Train r2 =' + str(train_r2[bestEpoch]) + ' Dev r2 =' + str(dev_r2[bestEpoch]))\n",
    "\n",
    "    # Plot training curves\n",
    "    #PlotTrainingCurves(train_r2,dev_r2,epochCount)\n",
    "\n",
    "    resultsArray[k,:] = [bestEpoch+1, train_loss[bestEpoch], dev_loss[bestEpoch], train_r2[bestEpoch], dev_r2[bestEpoch]]\n",
    "\n",
    "#results columns: nHiddenUnits, nHiddenLayers || bestEpoch, trainLoss, devLoss, trainR2, devR2\n",
    "\n",
    "results = np.concatenate((hyperParamsArray,resultsArray),axis=1)\n",
    "savetxt('hyperParamSearchResults.csv', results, delimiter=',')\n",
    "print(\"results saved to hyperParamSearchResults.csv!\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results saved to hyperParamSearchResults.csv!\n"
     ]
    }
   ],
   "source": [
    "results = np.concatenate((hyperParamsArray,resultsArray),axis=1)\n",
    "savetxt('hyperParamSearchResults.csv', results, delimiter=',')\n",
    "print(\"results saved to hyperParamSearchResults.csv!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save newly trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory for newly trained models\n",
    "if not os.path.isdir('NewlyTrainedModels'):\n",
    "    os.mkdir('NewlyTrainedModels')\n",
    "\n",
    "# Serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"NewlyTrainedModels/NeuralNet_\" + modeltype + \"_newModel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"NewlyTrainedModels/NeuralNet_\" + modeltype + \"_newModel_weights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Predictions\n",
    "Note that results may vary slightly from the paper for several reasons: <br />\n",
    "1) The models in the paper were trained with a GPU, results vary slightly when trained with CPU <br />\n",
    "2) Small floating-point differences when we re-packaged dataset for distribution <br />\n",
    "3) For test set results, we randomly sample 400 steps from each leg in the set (to mitigate the effect of walking speed or stride frequency on outcome metrics), while the results here are for all steps in the test set. We also bootstrap resampled the test set 10,000 times to compute the mean and confidence intervals of performance metrics, making the mean performance metric vary slightly from the results on the uniformly-sampled test set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on one of the data splits\n",
    "# Change BOTH INPUT AND LABELS for data split that you'd like to use for model evaluation\n",
    "inputForEval = testInput # options: trainInput, devInput, testInput\n",
    "labelsForEval = testLabels # options: trainLabels, devLabels, testLabels\n",
    "\n",
    "# Only after model hyperparameter tuning was finished, we evaluated on test set\n",
    "predictionsForEval = PredictMCF(model,inputForEval)\n",
    "\n",
    "# Plot predicted vs true KAM predictions\n",
    "PlotMCFpredictions(labelsForEval,predictionsForEval)\n",
    "\n",
    "# Print performance metrics\n",
    "evaluatedMetrics = r2_numpy(inputForEval,labelsForEval,model)\n",
    "print('r2 = ' + str(evaluatedMetrics[0]) + ', MSE = ' + str(evaluatedMetrics[1])+ ', MAE = ' + str(evaluatedMetrics[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "0470cb565e78f7d9937ae2ac9780bed6bd4f8cd3aac5e0eb1d265edac07126ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
